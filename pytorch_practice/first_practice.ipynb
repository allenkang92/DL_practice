{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 프레임워크란?\n",
    "딥러닝 뿐만 아니라 다양한 웹, 앱, 네트워크 등 다양한 프로그래밍 분야가 존재함.\n",
    "프로그램을 다룸에 있어서, 공통적으로 사용되는 기능들을 표준화된 소스코드로 만들어 놓고 사용할 수 있도록 제공하는 것 \n",
    "== 프레임워크\n",
    "\n",
    "딥러닝에도 기초 함수부터 복잡한 신경망 등이 구현되어 있는 여러 가지 프레임워크가 있고 pytorch도 그 중 하나임.\n",
    "\n",
    "2) 딥러닝 프레임워크의 종류와 특징\n",
    "개발에 사용되는 언어와 사용하는 방식에 따라 설계가 조금씩 달라지기 때문에 딥러닝 프레임워크도 그 숫자가 많다.\n",
    "그 중 대표적으로 사용되는 프레임워크는 텐서플로우, 파이토치 두 가지가 있음. \n",
    "\n",
    "![poster](./import_first.png)\n",
    "\n",
    "3) Define and Run vs. Define by Run\n",
    "Define and Run의 특징을 가지는 텐서플로우의 경우,\n",
    "- 실행할 계산에 관련된 그래프를 미리 정의하여 올려놓고\n",
    "- 그래프에 투입될 데이터들을 집어넣어 연산을 수행하는 방식.\n",
    "- 따라서, 한 번 실행이 된 상태에서 에러가 나면 찾기가 힘들다!\n",
    "\n",
    "반면 Define by Run의 특성을 가지고 있는 파이토치의 경우,\n",
    "- 연산이 이루어지는 시점에서 동적으로 그래프를 만들어 연산을 수행하기 때문에\n",
    "- 조금 더 낮은 단위의 연산들로 구성할 수 있게 되고\n",
    "- 디버깅 및 구조 설계의 세분화가 가능해짐!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Tensor\n",
    "파이토치를 공부하면서 가장 많이 볼 객체 중 하나. Tensor는 numpy에서 ndarray, 파이썬 내장 객체의 list와 유사한 배열 객체. \n",
    "엄밀히 말하면, list 객체보다 numpy의 ndarray와 가장 유사하다고 볼 수 있음. 따라서 Tensor 객체가 가지고 있는 여러 메서드나 Tensor 객체를 통해서 이루어지는 연산들은 numpy의 ndarray와 거의 동일.\n",
    "\n",
    "\n",
    "2) Squeeze vs Unsqueeze\n",
    "\n",
    "딥러닝을 학습하면서, 다양한 행렬 연산들을 수행하게 됨. \n",
    "그런데 행렬 연산시, 가장 중요한 게 행렬의 크기입니다. 행렬의 크기가 다른 경우, 다른 연산의 결과가 수행될 수 도 있습니다. 이를 위해서 PyTorch에서는 다양한 방식의 함수를 제공. \n",
    "그 중의 하나로 Squeeze와 Unsqueeze, 이를 통해서 행렬의 \"차원\"을 하나 더 높이거나 줄 일 수 있습니다. 예를들어 [1,2,3,4] 와 같은 행렬을 [[1,2,3,4]] 또는 [[1],[2],[3],[4]] 와 같이 변환 할 수 있습니다. 물론 그 반대도 가능.\n",
    "\n",
    "3) Broadcasting\n",
    "\n",
    "torch를 통해 행렬을 연산하다 보면, 두 행렬의 크기가 갖지 않아도 계산이 되는 경우가 종종 있습니다. 이 경우 작은 크기의 행렬이 큰 크기의 행렬의 차원으로 Broadcasting 되는 것인데요, 다음 예시를 통해 살펴보겠습니다. 만약 A라는 tensor에 2X4 크기의 다음과 같은 행렬 [[1,2,3,4],[5,6,7,8]] 이 할당되어 있고, B라는 행렬에 1X4 크기의 다음과 같은 [1,2,3,4] 라는 행렬이 할당 되어 있다고 해봅시다. 두 tensor를 더하면 어떻게 될까요? 정답은 크기가 작은 B행렬이 크기가 큰 A행렬로 Broadcasting되어 [[2,4,6,8],[6,8,10,12]] 라는 결과를 얻을 수 있게 됩니다.\n",
    "\n",
    "4) Matrix multiplication\n",
    "\n",
    "위에서 설명한대로 Broadcasting을 수행할 때, 행렬의 곱의 상황은 어떨까요? 우선 tensor에는 행렬 곱을 위한 mm, matmul 두가지의 메서드가 존재합니다. (메서드에 대해 잘 모르시면 tensor라는 객체가 가지고 있는 함수 라고 생각하시면 됩니다.) mm 메서드의 경우 Broadcasting을 지원하지 않고 matmul 메서드의 경우 지원합니다. 그럼 위와 같은 상황 A, B를 곱한다면 어떻게 연산이 이루어 질까요? 한번 직접 코드를 통해 실습하고 결과를 분석해보세요 :)\n",
    "\n",
    "5) nn.Functional\n",
    "\n",
    "PyTorch에서는 다양한 function들을 한번에 모아서 사용 할 수 있도록 하는 모듈인 nn.Functional을 제공합니다! 이를 통해서 sigmoid, tanh, cross entropy 등 다양한 함수들을 직접 구현하지 않아도 사용 할 수 있습니다 :)   nn.~ 으로 제공되는 함수들은 어떤게 있을까요? \n",
    "\n",
    "6) AutoGrad\n",
    "\n",
    "PyTorch의 핵심 기능 중 하나죠! 바로 자동 미분입니다. pytorch는 어떤 tensor에 대한 연산 정보들을 기억했다가 자동으로 미분해주는 기능이 있습니다. 바로 Tensor 객체의 requires_grad 인자를 True로 만들어 주면 되는데요!  xx  텐서에 대해서  2x^22x\n",
    "​2\n",
    "​​  같은 연산을 거쳤다고 해보겠습니다. 해당 미분의 값은  4x4x 가 되겠죠? 그럼 해당 값인 \"4\"를 미분 값으로 잘 가지고 있다가 연산에 필요할 때 적용하게 됩니다. 더 다양한 예시들을 실습을 통해 적용 해 보시면서 자동 미분의 편리함을 체화해 보세요! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) torch.nn.Module \n",
    "\n",
    "우리가 논문에 있는 모델을 구현한다고 가정해봅시다. 현재 많은 딥러닝 모델은 복잡한 구조로 되어있는 것처럼 보입니다. 하지만 사실은 몇 개의 코어 블록의 반복입니다.\n",
    "\n",
    "블록이란, 다양한 layer가 하나의 영역을 이루며 쌓여있는 구조를 말합니다. 그렇다면 PyTorch에 구현되어 있는 linear, conv 등 여러가지 layer들을 활용해 블록으로 구성한 후, 이를 활용해 모델링을 하면 편하겠죠?\n",
    "\n",
    "torch의 nn.Module은 모든 layer의 Base Class입니다. nn.Module을 상속 하여 새로운 block을 정의하고 앞서 존재하는 다양한 torch의 layer을 가져와 새로운 Neural Network class를 쉽게 만들 수 있습니다. \n",
    "\n",
    "nn.Parameter와 같은 함수를 통해 실제 학습하는 tensor를 정의할 수 있지만, 대부분 경우 torch에 구현되어 있는 layer를 가져와서 사용하기 때문에 직접 Parameter를 정의하여 활용하는 경우는 많이 없습니다.\n",
    "\n",
    " \n",
    "\n",
    "상속이란?\n",
    "\n",
    "공통으로 존재하는 기능들을 묶어서 구현한 기존 \"클래스\"를 새롭게 탄상할 클래스에 적용하여 불필요한 중복을 제거하고, 필요한 함수를 추가하거나 수정하는 방식을 통해 사용하고자 하는 방식으로 새로운 클래스를 정의하는 것을 말합니다.\n",
    "\n",
    "nn.Module을 재정의한 클래스에는 두가지 함수를 작성을 해줘야합니다. 예시를 통해 알아봅시다.\n",
    "\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weights = nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "    def forward(self, x : Tensor):\n",
    "        x = x @ self.weights \n",
    "        x = x + self.bias\n",
    "        return x \n",
    "1) __init__\n",
    "모델에서 활용될 layer을 정의합니다. nn.Parameter를 활용해 학습시킬 새로운 parameter를 정의하기도 합니다.\n",
    " \n",
    "2) forward \n",
    "__init__ 에서 정의한 layer들을 활용해 모델의 순전파 과정을 구현합니다. 강의에서 소개된 forward 과정이 실행됩니다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ") Loss function\n",
    "\n",
    "Loss function란, 입력값(Input)에 대한 Model의 출력값(Output)과  정답값(Label)의 차이를 비교해 모델의 출력값이 얼마나 잘 예측했는 가를 나타내는 함수입니다. Loss function에는 여러가지 함수 있는데 많이 쓰이는 함수에 대해 소개하면,\n",
    "\n",
    "MSE(Mean Squared Error) Loss  : 회귀(Regression)문제에서 많이 쓰이는 함수, 출력값(Output)과 정답값(Label)의 차이의 제곱에 대해 측정한다.\n",
    "CE(Cross Entropy) Loss: 분류(Classification)문제에서 많이 쓰이는 함수\n",
    " \n",
    "\n",
    "2) Backward\n",
    "\n",
    "Forward를 수행했다면, 이제 Backward를 할 차례입니다!\n",
    "\n",
    "1) (Forward 과정을 통해 얻어진) Model의 출력값(Output)과 정답값(Label)의 차이를 Loss Function을 통해 계산하여 Loss 값을 얻습니다.\n",
    "\n",
    "2) Backward는 Loss 값을 활용해 미분을 수행하고, back-propagation을 통해 Parameter(weight)를 update합니다.\n",
    "\n",
    " \n",
    "\n",
    "해당 과정을 통해 네트워크가 더 나은 Parameter(weight)를 가질 수 있게 됩니다. 코드 상에서 위의 과정이 어떻게 진행되는지 파악하는 것이 가장 중요합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Dataset \n",
    "\n",
    "우리가 갖고 있는 데이터셋을 모델에 입력한다고 했을 때에, 모델이 정의하고 있는 입력 형태로 데이터를 가공해줘야겠죠. 이때, Dataset 클래스를 통해 입력 형태를 정의할 수 있습니다. Dataset 클래스를 상속받아 Custom Dataset을 만들 때, 세가지 함수(init, len, getitem)를 구현해야 합니다.\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, text, labels):\n",
    "    # 초기 데이터 생성 방법을 지정\n",
    "    self.labels = labels\n",
    "    self.data = text\n",
    "  def __len__(self):\n",
    "    # 데이터의 전체 길이 return\n",
    "    return len(self.labels)\n",
    "  def __getitem__(self, idx):\n",
    "    # index 값을 주었을 때 반환되는 데이터의 형태 (X, y)\n",
    "    label = self.labels[idx]\n",
    "    text = self.data[idx]\n",
    "    sample = {\"Text\": text, \"Class\": label}\n",
    "    return sample\n",
    "\n",
    "\n",
    "2) DataLoader\n",
    "\n",
    "DataLoader는 Dataset을 입력으로 받아 Batch를 생성하고, Batch 생성시 데이터 shuffle, sampling 작업을 한다던지, Tensor로 변환 작업을 할 수 있는 class입니다. \n",
    "\n",
    "text = ['Happy', 'Amazing', 'Sad', 'Unhapy', 'Glum']\n",
    "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
    "# Dataset 생성\n",
    "MyDataset = CustomDataset(text, labels)\n",
    "# DataLoader 생성(Batch의 크기 2, 매 epoch마다 데이터셋 shuffle)\n",
    "MyDataLoader = DataLoader(MyDataset, batch_size=2, shuffle=True)\n",
    "for dataset in MyDataLoader:\n",
    "  print(dataset)\n",
    "# {'Text': ['Glum', 'Unhapy'], 'Class': ['Negative', 'Negative']}\n",
    "# {'Text': ['Sad', 'Amazing'], 'Class': ['Negative', 'Positive']}\n",
    "# {'Text': ['Happy'], 'Class': ['Positive']}\n",
    "DataLoader에는 여러 파라미터가 있어 필요시 적절한 파라미터를 활용해 여러 설정을 줄 수 있습니다. 그 중 강의에서도 소개된 collate_fn에 대해 조금만 더 살펴봅시다.\n",
    "\n",
    " \n",
    "\n",
    "3) 예제를 통해 알아보는 collate_fn\n",
    "\n",
    "다음과 같이 input의 길이가 각각 다른 Dataset이 있다고 가정합시다. \n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch\n",
    "\n",
    "class ExampleDataset(Dataset):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\"X\":torch.tensor([idx] * (idx+1), dtype=torch.float32), \n",
    "                \"y\": torch.tensor(idx, dtype=torch.float32)}\n",
    "\n",
    "dataset_example = ExampleDataset(num = 10)\n",
    "dataloader_example = torch.utils.data.DataLoader(dataset_example, batch_size= 1)\n",
    "for d in dataloader_example:\n",
    "    print('X : ',d['X'])\n",
    "프린트 결과 값\n",
    "\n",
    "'''\n",
    "X :  tensor([[0.]])\n",
    "X :  tensor([[1., 1.]])\n",
    "X :  tensor([[2., 2., 2.]])\n",
    "X :  tensor([[3., 3., 3., 3.]])\n",
    "X :  tensor([[4., 4., 4., 4., 4.]])\n",
    "X :  tensor([[5., 5., 5., 5., 5., 5.]])\n",
    "X :  tensor([[6., 6., 6., 6., 6., 6., 6.]])\n",
    "X :  tensor([[7., 7., 7., 7., 7., 7., 7., 7.]])\n",
    "X :  tensor([[8., 8., 8., 8., 8., 8., 8., 8., 8.]])\n",
    "X :  tensor([[9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]])\n",
    "'''\n",
    "이는 Batch size가 1이라면 전혀 상관이 없어 보입니다. 하지만 Batch Size를 2로 설정하면 어떻게 될까요?\n",
    "\n",
    "dataloader_example = torch.utils.data.DataLoader(dataset_example, batch_size = 2)\n",
    "for d in dataloader_example:\n",
    "    print(d['X'])\n",
    "프린트 결과 값\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "<ipython-input-11-449346496a83> in <module>()\n",
    "      1 dataloader_example = torch.utils.data.DataLoader(dataset_example, batch_size = 2)\n",
    "----> 2 for d in dataloader_example:\n",
    "      3     print(d['X'])\n",
    "\n",
    "5 frames\n",
    "/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py in default_collate(batch)\n",
    "    136             storage = elem.storage()._new_shared(numel)\n",
    "    137             out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n",
    "--> 138         return torch.stack(batch, 0, out=out)\n",
    "    139     elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "    140             and elem_type.__name__ != 'string_':\n",
    "\n",
    "RuntimeError: stack expects each tensor to be equal size, but got [1] at entry 0 and [2] at entry 1\n",
    "위와 같이 오류가 나는 걸 볼 수 있는데요, 이는 같은 배치 안의 input(X)의 길이가 다르기 때문입니다. 이 오류를 해결하기 위해서는 input의 길이를 동일하게 맞춰주어야 함으로, 같은 배치 안에 길이가 가장 긴 input에 맞춰 다른 input들에 임의로 0값을 넣어줍니다. (Zero padding)\n",
    "\n",
    "def my_collate_fn(samples):\n",
    "    collate_X = []\n",
    "    collate_y = []\n",
    "    max_len = max([len(sample['X']) for sample in samples])\n",
    "    for sample in samples:\n",
    "        diff = max_len-len(sample['X'])\n",
    "        if diff > 0:\n",
    "            zero_pad = torch.zeros(size=(diff,))\n",
    "            collate_X.append(torch.cat([sample['X'], zero_pad], dim=0))\n",
    "        else:\n",
    "            collate_X.append(sample['X'])\n",
    "    collate_y = [sample['y'] for sample in samples]\n",
    "    return {'X': torch.stack(collate_X),\n",
    "             'y': torch.stack(collate_y)}\n",
    "\n",
    "dataloader_example = torch.utils.data.DataLoader(dataset_example, \n",
    "                                                 batch_size=2,\n",
    "                                                 collate_fn=my_collate_fn)\n",
    "for d in dataloader_example:\n",
    "    print(d['X'], d['y'])\n",
    "프린트 결과\n",
    "\n",
    "\"\"\"\n",
    "tensor([[0., 0.],\n",
    "        [1., 1.]]) tensor([0., 1.])\n",
    "tensor([[2., 2., 2., 0.],\n",
    "        [3., 3., 3., 3.]]) tensor([2., 3.])\n",
    "tensor([[4., 4., 4., 4., 4., 0.],\n",
    "        [5., 5., 5., 5., 5., 5.]]) tensor([4., 5.])\n",
    "tensor([[6., 6., 6., 6., 6., 6., 6., 0.],\n",
    "        [7., 7., 7., 7., 7., 7., 7., 7.]]) tensor([6., 7.])\n",
    "tensor([[8., 8., 8., 8., 8., 8., 8., 8., 8., 0.],\n",
    "        [9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]]) tensor([8., 9.])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Checkpoint\n",
    "\n",
    "Checkpoint란 모델을 저장한 하나의 분기점을 말합니다. Checkpoint는 왜 필요할까요?\n",
    "\n",
    "일반적인 경우로 모델을 학습시킬 때에 우리는 시간이 얼마나 걸릴지, 또 얼만큼을 진행할지 확신하지 못합니다. 이때에 Checkpoint를 여러 개 만들어 두면 1개의 학습을 진행하면서 다른 실험을 병행할 수도 있고, 필요하다면 책을 조금 더 읽을 수도 있습니다.\n",
    "\n",
    "Checkpoint를 활용할 수 있는 대표적인 예시를 들어보겠습니다.\n",
    "\n",
    "학습을 진행하다가 최적의 상태가 된다고 판단되는 경우\n",
    "다양한 모델의 분기를 만들어서 모델들의 집단 지성을 이용하고 싶은 경우\n",
    "학습 도중에 컴퓨터에 이상이 생겨서 학습이 중단되는 경우\n",
    "이 밖에도 다양한 상황에 분기를 만들어 활용하고 모델 학습의 안정성을 높이는 것이 Checkpoint의 목표입니다. 앞서 배운 모델 저장 방식을 그대로 활용해 적절한 분기 조건을 정하고, torch.save를 실행시키는 식으로 코드를 작성하면 됩니다.\n",
    "\n",
    "기존에 배웠던 방식에 추가된 점은 학습의 결과물로 표현되는 여러가지 정보들을 함께 저장하여 어떤 Checkpoint가 가장 이상적인지를 확인 할 수 있도록 하는 부분 입니다. 이번 강의를 통하여 모델의 여러가지 Checkpoint 분기를 설정해 학습시 적용해 보는 연습을 해보면 좋겠습니다 :)\n",
    "\n",
    " \n",
    "\n",
    "2) Earlystopping\n",
    "\n",
    "Earlystopping이란, 모델이 학습을 거듭하는 과정 중 최적이라고 판단되는 지점에서 학습을 조기 종료하는 기법입니다. 최적의 상태를 판단하기 위해 모델의 지표를 모니터링하여 꾸준히 좋은 지표가 유지되는지를 고려합니다.\n",
    "\n",
    "예를 들어, 모델이 전체 데이터를 3번쯤 학습한 뒤 현재 학습 데이터에 대한 정확도가 90% 가 되었다고 가정해 봅시다. 다음 4번째, 5번째를 거듭하는데 학습이 진행될수록, 오히려 정확도가 88%, 85%로 떨어지는 경우를 발견하게 됩니다. 이럴 경우 5번째에서 Earlystopping을 수행하면서 학습을 조기 종료할 수 있게 합니다.\n",
    "\n",
    "\n",
    "\n",
    "3) Metric\n",
    "\n",
    "Metric이란, 모델의 성능을 측정하기 위한 지표들을 의미합니다. 제일 보편적인 지표인 정확도(Accuracy)가 있고, 우리가 풀고자하는 문제에 맞는 다양한 지표가 존재합니다. 모델을 학습시킬 때, 적합한 metric을 선정하는 것도 중요한 요소 중 하나입니다.\n",
    "\n",
    "쉬운 이해를 위해, 자연어 모델이 해결하는 문제를 예시로 들어보겠습니다.\n",
    "\n",
    "사람들이 주고받은 문자 데이터를 입력으로 받아 요약본을 출력하는 모델을 학습시킨다고 해봅시다. 아래와 같이 요약문을 어떻게 작성하고 싶은지에 따라 모델의 성능 지표를 다르게 설정할 수 있겠죠.\n",
    "\n",
    "방법 1. 핵심 단어를 추출하는 방법\n",
    "방법 2. 문단의 맥락을 이해하여 새로운 문장을 만드는 방법\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Pre-trained Model & Transfer Learning\n",
    "\n",
    "Pre-trained 모델이란, 사전에 학습된 모델을 의미합니다. 그럼 이런 Pre-trained 기법은 왜 사용하는 것 일까요?\n",
    "\n",
    "가장 핵심적인 이유는 유사한 문제를 학습한 모델로부터 좋은 초기 값을 얻기 위해서 입니다.\n",
    "\n",
    "쉬운 이해를 위해 이미지 데이터를 예시로 들어보겠습니다.\n",
    "\n",
    "이미지를 분류하기 위해 모델 A를 사용하고자 합니다. 모델 A의 파라미터는 제법 커서 많은 정보들을 담을 수 있습니다. 하지만 지금 가지고 있는 데이터는 100~200장 정도로 작은 데이터셋이라, 이 데이터로 모든 파라미터를 학습시킨다면 좋은 결과를 얻기가 어려울 것 같네요. 이럴 경우 커다란 데이터 셋으로 이미 사전에 학습되어 있는 Pre-trained 모델을 불러와 가지고 있는 데이터를 추가로 학습시켜 문제를 해결 하게 됩니다.\n",
    "\n",
    "이미 큰 데이터로 사전 학습하여 다양한 정보가 반영된 모델에, 현재 풀고자 하는 문제 데이터인 200장 정도의 이미지를 학습시켜 문제를 더 잘 해결 하도록 하는 것이지요. 이 과정을 Transfer learning 이라고 합니다. 말그대로 기존에 학습된 파라미터를 새로운 문제에 \"전이\" 시키도록 학습하게 됩니다.\n",
    "\n",
    "이런 사전 학습 모델의 직관적인 이해는 \"모델이 일반적인 상황의 데이터를 충분히 학습했다면, 그에 대한 정보를 잘 가지고 있을 것이고, 풀고자 하는 문제의 특성이 유사하다면 적은 수의 데이터로 전체 네트워크를 처음부터 학습시키는 것 보다 좋은 성능을 낼 것\"으로 기대한다는 점 입니다.\n",
    "\n",
    "만약 사전 학습된 데이터가 현재 풀고자 하는 문제 데이터와 그렇게 유사하지는 않다면 Pre-trained 모델을 사용하여 Transfer learning 하는 과정이 의미가 있을까요? 한번 생각해 보시면 좋겠습니다 :)\n",
    "\n",
    "\n",
    "\n",
    "2) Freezing\n",
    "\n",
    "Freezing 기법은 Transfer learning을 진행할 때에 Pre-trained 모델의 학습 파라미터들을 update 하지 않고 \"얼려둔\" 상태로 학습하는 것을 말합니다. 이 방식을 통해서 기존의 학습 파라미터를 통해 나오게 되는 결과 값에 추가 파라미터를 부착하여 그 부분만 update 되도록 하는 기법입니다. 이를 통해 필요한 만큼의 파라미터를 효율적으로 update하여 연산속도를 올리고 빠른 결과를 내는 것이 목적입니다.\n",
    "\n",
    "앞서 Auto Grad를 배울 때, Tensor에 사용했던 requires_grad를 기억하시나요? 만약 그 옵션이 False가 된다면 어떨까요?\n",
    "\n",
    "네 맞습니다. 파라미터를 update하지 않는 상태로 바뀌게 되겠죠. 해당 방식을 통해서 freezing을 구현하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Machine learning project template (머신러닝 프로젝트 템플릿)\n",
    "\n",
    "PyTorch를 포함한 다양한 프레임워크를 통해 AI 모델이 생성됩니다. 'AI 모델이 만들어지는 과정을 정형화할 수는 없을까요?' 라는 질문으로 시작한 결과가 프로젝트의 템플릿입니다. 사실 \"프로젝트 템플릿\" 이라는 개념은 딥러닝 외 분야에서도 사용되는 상당히 포괄적인 개념입니다. 세상에는 다양한 형태의 소프트웨어가 존재하고, 이를 개발하기 위해서 만들어진 정형화된 템플릿이 존재합니다. \"머신러닝 모델 개발\" 도 그 중에 하나입니다.\n",
    "\n",
    "머신러닝 모델이 개발되는 과정을 생각해 봅시다. 아래와 같이 간단히 5가지 정도의 절차로 정형화할 수 있을 것으로 보입니다.\n",
    "\n",
    "(1)데이터 전처리 -> (2)모델 아키텍쳐 구축 -> (3)모델 학습 -> (4)모델 검증 -> (5)모델 배포\n",
    "\n",
    "머신러닝 프로젝트 템플릿이란, 이러한 일련의 과정들을 잘 정형화 해서 구조화 해놓은 것을 의미합니다.\n",
    "\n",
    "해당 강의를 통해 그 예시를 학습하면서 어떻게 함수들이 구조화 되어 있는지 확인해 보세요 :)\n",
    "\n",
    " \n",
    "\n",
    "2) OOP (Object Oriented Programming, 객체지향 프로그래밍)\n",
    "\n",
    "OOP(객체지향 프로그래밍)은 프로그램 코드를 하나의 \"객체\"로 생각하는 방식의 구현입니다. 여기서 객체란, 다른 객체와 상호작용 하고 값을 주고 받으며 행동하는 하나의 주체를 의미합니다.\n",
    "\n",
    "예를 들어 \"사람\" 이라는 객체의 공통적인 패턴을 정의한다고 생각해 봅시다. 다양한 경우가 있겠지만, \"이동\"에 관련된 함수들을 구현하다고 한다면, 걷기 / 뛰기 / 구르기 / 기어가기 등의 함수가 구현될 수 있습니다. 이 때, \"사람\" 이라는 \"클래스\"를 하나의 객체로 표현하여 프로그래밍 하게 됩니다.\n",
    "\n",
    "그런데 \"이름\" 은 어떨까요? \"이름\"이라는 객체는 각 사람마다 고유적으로 가질 수 있고, 어쩌면 서로를 구분하는 값으로 서로 다른 경우가 많을 것입니다. 이런 경우 객체를 생성할 때 \"이름\" 이라는 속성을 부여해 하나의 \"인스턴스\"를 생성합니다.\n",
    "\n",
    "\"홍길동\" 씨와 \"강감찬\" 씨는 서로 다른 것처럼, 각각의 인스턴스들은 \"클래스\"로부터 공통적인 속성들을 부여받고 인스턴스마다의 특징을 생성 시점에 반영하도록 프로그래밍 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Logging\n",
    "\n",
    "Logging이란, 학습이 진행되면서 주요하다고 생각되는 지표들이나 학습의 상태 등 관련된 정보들을 기록하는 것을 의미합니다. PyTorch를 사용하면서 보통의 경우 코드 블럭의 중간중간 파이썬 내장 함수인 print를 사용해서 정보들을 기록하곤 합니다. 하지만 이런 방법은 저장, 수정, 시각적으로 보기 불편함 등의 문제점이 존재합니다. 이를 해결하기 위해서 다양한 시각화 툴들이 있는데요 대표적으로 사용되는Tensorboard와 WandB를 소개합니다.\n",
    "\n",
    "\n",
    "\n",
    "2) Tensorboard\n",
    "\n",
    "Tensorboard는 TensorFlow의 프로젝트로 만들어진 시각화 도구로 학습 그래프, Metric, 학습 결과의 시각화를 지원합니다. PyTorch도 연결하여 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "3) Weight & Biases\n",
    "\n",
    "머신러닝 실험을 원활하게 지원하기 위한 상용 도구로써, 협업, code versioning, 실험 결과 기록 등의 기능을 제공하는 시각화 툴입니다. MLOps의 대표적인 툴으로 확대되고 있을만큼 소개된 내용 이외에도 다양한 기능들이 존재합니다.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 하이퍼 파라미터 튜닝이란?\n",
    "\n",
    "모델을 학습하는 과정에 있어 사람이 임의로 지정해주는 값들이 있는데, 이를 하이퍼 파라미터라 합니다. 그 예로는 learning rate, layer의 수, optimzer의 종류가 있습니다.\n",
    "\n",
    "하이퍼 파라미터를 어떤 값으로 지정하느냐에 따라 모델 성능에 차이가 있기 때문에, 주로 기본적인 성능이 보장된 이후에 하이퍼 파라미터의 수정을 조금씩 진행하는데요. 이를 통해 모델의 성능을 끌어올리는 과정이며 이를 하이퍼 파라미터 튜닝이라고 합니다. 하이퍼 파라미터 튜닝 방법은 대표적으로 두가지가 있습니다.\n",
    "\n",
    "첫번째 방법론은 Grid Search가 있습니다. 하이퍼 파라미터 각각에 탐색할 값들을 지정하고 모든 경우의 수를 실험해보는 방법론을 말합니다. 예를 들어, 하이퍼파라미터는 Batch사이즈, learning rate이 있고 각각 Batch 사이즈는 [32, 64, 128], Learning rate은 [0.1, 0.01, 0.001] 을 탐색한다고 하면, 3X3=9번의 실험을 통해 최적의 조합을 찾습니다. \n",
    "\n",
    "두번째 방법론은 Random search입니다. Grid search와 다른 점은 탐색할 값들을 지정하지 않고 범위만 지정한 다음 그 안에서 각각 하이퍼파라미터 값을 랜덤하게 뽑아서 최적의 조합을 찾는 방법론입니다.\n",
    "\n",
    "이외에도 두 방법론을 같이 사용해서 Random Search를 통해 성능이 잘나오는 구간을 확인하고 Grid search를 통해 값들을 꼼꼼히 확인하는 방법도 있습니다. \n",
    "\n",
    " \n",
    "\n",
    "2) Ray란? \n",
    "\n",
    "Ray는 머신러닝/딥러닝을 할 때 분산 처리를 효과적으로 처리할 수 있도록 도와주는 라이브러리입니다. 머신러닝/딥러닝 모델 학습 전반 뿐 아니라 강화학습, 모델 서빙에서도 활용할 수 있습니다. Ray tune을 통해 Hyperparameter tuning을 위한 다양한 모듈을 제공하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) OOM(Out Of Memory)란?\n",
    "\n",
    "우리가 사용하는 GPU도 또한 memory 크기가 정해져 있습니다. 'Out of Memory'는 사용하고 있는 GPU의 메모리 이상으로 할당하면서 발생하는 오류를 말합니다. 딥러닝 모델링 학습시 자주 만나는 오류 중 하나입니다. 모델의 사이즈를 줄이지 않으면서 OOM 오류를 해결하는 방법엔 어떤 것이 있을까요?\n",
    "\n",
    "우선 Batch size를 줄이는 방법이 있습니다. Batch Size를 줄여서 GPU에 할당되는 메모리를 줄여 OOM을 방지 할 수 있습니다.\n",
    "\n",
    "둘째로는 훈련과정에서 낭비되는 memory를 줄이는 방법이 있습니다. torch.cuda.empty_cache()를 통해서 사용되지 않는 cache를 정리할 수 있습니다. trainning loop에서 불필요한 변수를 적절히 del 명령어를 통해 삭제를 하거나 python 기본 객체로 변환하여 처리를 할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
